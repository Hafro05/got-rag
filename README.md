Parfait, un bon `README.md` peut vraiment valoriser ton projet, surtout si tu le publies sur GitHub ou Hugging Face. Voici un **exemple de README professionnel, clair et attractif**, que tu pourras adapter Ã  ton projet `got_rag`.

---

```markdown
# ğŸ‰ Game of Thrones RAG App

Un projet de **RAG (Retrieval-Augmented Generation)** en franÃ§ais, basÃ© sur le texte de *Game of Thrones*, qui permet de poser des questions en langage naturel et d'obtenir des rÃ©ponses prÃ©cises provenant d'un corpus personnalisÃ©.

> ğŸ” "Qui est le pÃ¨re de Jon Snow ?" â†’ RÃ©ponse gÃ©nÃ©rÃ©e Ã  partir du livre, pas juste inventÃ©e par le LLM.

---

## ğŸ§  FonctionnalitÃ©s

- âœ… ModÃ¨le LLM franÃ§ais pour gÃ©nÃ©rer les rÃ©ponses
- âœ… Base de vecteurs (FAISS) pour retrouver les passages pertinents dans le livre
- âœ… Interface web simple via Flask (ou Gradio selon version)
- âœ… Structure modulaire pour facilement rÃ©utiliser avec d'autres corpus

---

## ğŸ“‚ Arborescence du projet

```

got\_rag/
â”‚
â”œâ”€â”€ app/                  # Application Flask
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ style.css
â”œâ”€â”€ data/
â”‚   â””â”€â”€  got.txt               # Corpus principal (texte GOT)
â”œâ”€â”€ got\_rag/              # Modules du backend
â”‚   â”œâ”€â”€ loader.py         # Chargement et dÃ©coupage du texte
â”‚   â”œâ”€â”€ embedder.py       # Embedding + FAISS
â”‚   â””â”€â”€ rag_chain.py             # ChaÃ®ne RAG
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## ğŸ”§ Installation locale

### 1. Cloner le repo

```bash
git clone https://github.com/Hafro05/got_rag.git
cd got_rag
````

### 2. CrÃ©er l'environnement

```bash
python -m venv venv
source venv/bin/activate   # ou venv\Scripts\activate sous Windows
pip install -r requirements.txt
```

### 3. Lancer l'app

```bash
python app/app.py
```

AccÃ©dez Ã  [http://localhost:5000](http://localhost:5000)

---

## ğŸ” Ã€ propos du RAG

Ce projet utilise un pipeline de type **RAG (Retrieval-Augmented Generation)** :

1. ğŸ” Les questions sont vectorisÃ©es et comparÃ©es aux chunks du corpus via FAISS.
2. ğŸ“š Les passages pertinents sont extraits.
3. ğŸ§  Un LLM franÃ§ais gÃ©nÃ¨re une rÃ©ponse en se basant sur ces extraits.

---

## ğŸ› ï¸ ModÃ¨les utilisÃ©s

| Type           | ModÃ¨le                                                        | Source       |
| -------------- | ------------------------------------------------------------- | ------------ |
| Embedding      | `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` | Hugging Face |
| LLM (franÃ§ais) | `google/flan-t5-base` (`mistralai/Mistral-7B-Instruct-v0.1`)  | Hugging Face |

ğŸ’¡ Tu peux facilement modifier ces modÃ¨les dans le fichier `embedder.py` et `rag_gain.py`.

---

## ğŸŒ DÃ©ploiement

### Option 1 : Hugging Face Spaces

* Code basÃ© sur `Gradio`
* Facile Ã  hÃ©berger gratuitement

### Option 2 : Render / Railway / VPS

* Serveur Flask via Gunicorn
* Dockerisable si besoin (voir Dockerfile Ã  venir)

---

## ğŸ§¾ Licence

Projet open source sous licence MIT.

---

## ğŸ‘¤ Auteur

> RÃ©alisÃ© par Hafro05
> PassionnÃ© par lâ€™IA, le NLP, et lâ€™univers de George R.R. Martin

---

## ğŸ™ Remerciements

* ğŸ¤— [Hugging Face](https://huggingface.co)
* ğŸ“š [LangChain](https://www.langchain.com/)
* ğŸ“˜ Lâ€™Å“uvre de George R. R. Martin

---

## âœ¨ TODO

* [ ] Ajouter dâ€™autres livres (Tome 2, 3â€¦)
* [ ] Mode conversationnel (chat avec mÃ©moire)
* [ ] Support audio avec Whisper

